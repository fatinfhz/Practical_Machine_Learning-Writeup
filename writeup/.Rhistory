#Fatin Fatihah Zahari
#Exploratory Data Analysis
#Project 1 - plot3.R for plot3.png
#Fetch Raw Data
rawFile <- "./data/household_power_consumption.txt"
mydata<- read.table(rawFile, header=TRUE, sep=";", stringsAsFactors=FALSE, dec=".")
subsetmydata <- mydata[mydata$Date %in% c("1/2/2007","2/2/2007") ,]
#Data Analysis
datetime<-strptime(paste(subsetmydata$Date, subsetmydata$Time, sep=""), "%d/%m/%Y %H:%M:%S")
globalactivepower <- as.numeric(subsetmydata$Global_active_power)
subsetmeter1<-as.numeric(subsetmydata$Sub_metering_1)
subsetmeter2<-as.numeric(subsetmydata$Sub_metering_2)
subsetmeter3<-as.numeric(subsetmydata$Sub_metering_3)
png("plot3.png", width=480, height=480)
plot(datetime, subsetmeter1, type="l", ylab="Energy sub metering", xlab="")
lines(datetime, subsetmeter2, type="l", col="red")
lines(datetime, subsetmeter3, type="l", col="blue")
legend("topright", c("Sub_metering_1", "Sub_metering_2", "Sub_metering_3"), lty=1, lwd=2.5, col=c("black", "red", "blue"))
dev.off()
#Fatin Fatihah Zahari
#Exploratory Data Analysis
#Project 1 - plot3.R for plot3.png
#Fetch Raw Data
rawFile <- "./data/household_power_consumption.txt"
mydata<- read.table(rawFile, header=TRUE, sep=";", stringsAsFactors=FALSE, dec=".")
mydata<- read.table(rawFile, header=TRUE, sep=";", stringsAsFactors=FALSE, dec=".")
getwd()
setwd("C:/Users/Gn0145/Desktop/-/R/r2")
getwd()
#Fatin Fatihah Zahari
#Exploratory Data Analysis
#Project 1 - plot3.R for plot3.png
#Fetch Raw Data
rawFile <- "./data/household_power_consumption.txt"
mydata<- read.table(rawFile, header=TRUE, sep=";", stringsAsFactors=FALSE, dec=".")
subsetmydata <- mydata[mydata$Date %in% c("1/2/2007","2/2/2007") ,]
#Data Analysis
datetime<-strptime(paste(subsetmydata$Date, subsetmydata$Time, sep=""), "%d/%m/%Y %H:%M:%S")
globalactivepower <- as.numeric(subsetmydata$Global_active_power)
subsetmeter1<-as.numeric(subsetmydata$Sub_metering_1)
subsetmeter2<-as.numeric(subsetmydata$Sub_metering_2)
subsetmeter3<-as.numeric(subsetmydata$Sub_metering_3)
png("plot3.png", width=480, height=480)
plot(datetime, subsetmeter1, type="l", ylab="Energy sub metering", xlab="")
lines(datetime, subsetmeter2, type="l", col="red")
lines(datetime, subsetmeter3, type="l", col="blue")
legend("topright", c("Sub_metering_1", "Sub_metering_2", "Sub_metering_3"), lty=1, lwd=2.5, col=c("black", "red", "blue"))
dev.off()
#Fatin Fatihah Zahari
#Exploratory Data Analysis
#Project 2 | plot5.R , plot5.png
#Create name accordingly
if(!exists("NEI")){
NEI <- readRDS("./data/summarySCC_PM25.rds")
}
if(!exists("SCC")){
SCC <- readRDS("./data/Source_Classification_Code.rds")
}
# merge the two data sets
if(!exists("NEISCC")){
NEISCC <- merge(NEI, SCC, by="SCC")
}
#Data Analysis
library(ggplot2)
# How have emissions from motor vehicle sources changed from 1999-2008 in Baltimore City?
# 24510 is Baltimore, see plot2.R
# Searching for ON-ROAD type in NEI
# Don't actually know it this is the intention, but searching for 'motor' in SCC only gave a subset (non-cars)
subsetNEI <- NEI[NEI$fips=="24510" & NEI$type=="ON-ROAD",  ]
aggregatebyyear<- aggregate(Emissions ~ year, subsetNEI, sum)
#Call device
png("plot5.png", width=840, height=480)
g <- ggplot(aggregatebyyear, aes(factor(year), Emissions))
g <- g + geom_bar(stat="identity") +
xlab("year") +
ylab(expression('Total PM'[2.5]*" Emissions")) +
ggtitle('Total Emissions from motor vehicle (type = ON-ROAD) in Baltimore City, Maryland (fips = "24510") from 1999 to 2008')
print(g)
dev.off()
library("ggplot2", lib.loc="~/R/win-library/3.2")
#Fatin Fatihah Zahari
#Exploratory Data Analysis
#Project 2 | plot5.R , plot5.png
#Create name accordingly
if(!exists("NEI")){
NEI <- readRDS("./data/summarySCC_PM25.rds")
}
if(!exists("SCC")){
SCC <- readRDS("./data/Source_Classification_Code.rds")
}
# merge the two data sets
if(!exists("NEISCC")){
NEISCC <- merge(NEI, SCC, by="SCC")
}
#Data Analysis
library(ggplot2)
# How have emissions from motor vehicle sources changed from 1999-2008 in Baltimore City?
# 24510 is Baltimore, see plot2.R
# Searching for ON-ROAD type in NEI
# Don't actually know it this is the intention, but searching for 'motor' in SCC only gave a subset (non-cars)
subsetNEI <- NEI[NEI$fips=="24510" & NEI$type=="ON-ROAD",  ]
aggregatebyyear<- aggregate(Emissions ~ year, subsetNEI, sum)
#Call device
png("plot5.png", width=840, height=480)
g <- ggplot(aggregatebyyear, aes(factor(year), Emissions))
g <- g + geom_bar(stat="identity") +
xlab("year") +
ylab(expression('Total PM'[2.5]*" Emissions")) +
ggtitle('Total Emissions from motor vehicle (type = ON-ROAD) in Baltimore City, Maryland (fips = "24510") from 1999 to 2008')
print(g)
dev.off()
getwd()
setwd(C:/Users/Gn0145/Desktop/-/4/R)
setwd(C:/Users/Gn0145/Desktop/-/4/R)
setwd(C:/Users/Gn0145/Desktop/-/4/R)
setwd(C:/Users/Gn0145/Desktop/-/4/R)
setwd(C:Users/Gn0145/Desktop/-/4/R)
getwd()
#Fatin Fatihah Zahari
#Exploratory Data Analysis
#Project 2 | plot5.R , plot5.png
#Create name accordingly
if(!exists("NEI")){
NEI <- readRDS("./data/summarySCC_PM25.rds")
}
if(!exists("SCC")){
SCC <- readRDS("./data/Source_Classification_Code.rds")
}
# merge the two data sets
if(!exists("NEISCC")){
NEISCC <- merge(NEI, SCC, by="SCC")
}
#Data Analysis
library(ggplot2)
# How have emissions from motor vehicle sources changed from 1999-2008 in Baltimore City?
# 24510 is Baltimore, see plot2.R
# Searching for ON-ROAD type in NEI
# Don't actually know it this is the intention, but searching for 'motor' in SCC only gave a subset (non-cars)
subsetNEI <- NEI[NEI$fips=="24510" & NEI$type=="ON-ROAD",  ]
aggregatebyyear<- aggregate(Emissions ~ year, subsetNEI, sum)
#Call device
png("plot5.png", width=840, height=480)
g <- ggplot(aggregatebyyear, aes(factor(year), Emissions))
g <- g + geom_bar(stat="identity") +
xlab("year") +
ylab(expression('Total PM'[2.5]*" Emissions")) +
ggtitle('Total Emissions from motor vehicle (type = ON-ROAD) in Baltimore City, Maryland (fips = "24510") from 1999 to 2008')
print(g)
dev.off()
#Fatin Fatihah Zahari
#Exploratory Data Analysis
#Project 2 | plot6.R , plot6.png
#Create name accordingly
if(!exists("NEI")){
NEI <- readRDS("./data/summarySCC_PM25.rds")
}
if(!exists("SCC")){
SCC <- readRDS("./data/Source_Classification_Code.rds")
}
# merge the two data sets
if(!exists("NEISCC")){
NEISCC <- merge(NEI, SCC, by="SCC")
}
#Data Analysis
library(ggplot2)
# Compare emissions from motor vehicle sources in Baltimore City with emissions from motor
# vehicle sources in Los Angeles County, California (fips == "06037").
# Which city has seen greater changes over time in motor vehicle emissions?
# 24510 is Baltimore, see plot2.R, 06037 is LA CA
# Searching for ON-ROAD type in NEI
# Don't actually know it this is the intention, but searching for 'motor' in SCC only gave a subset (non-cars)
subsetNEI <- NEI[(NEI$fips=="24510"|NEI$fips=="06037") & NEI$type=="ON-ROAD",  ]
aggregatebyyearandfips <- aggregate(Emissions ~ year + fips, subsetNEI, sum)
aggregatebyyearandfips$fips[aggregatebyyearandfips$fips=="24510"] <- "Baltimore, MD"
aggregatebyyearandfips$fips[aggregatebyyearandfips$fips=="06037"] <- "Los Angeles, CA"
#Call device
png("plot6.png", width=1040, height=480)
g <- ggplot(aggregatebyyearandfips, aes(factor(year), Emissions))
g <- g + facet_grid(. ~ fips)
g <- g + geom_bar(stat="identity")  +
xlab("year") +
ylab(expression('Total PM'[2.5]*" Emissions")) +
ggtitle('Total Emissions from motor vehicle (type=ON-ROAD) in Baltimore City, MD (fips = "24510") vs Los Angeles, CA (fips = "06037")  1999-2008')
print(g)
dev.off()
?NEI
?dplyr
??dplyr
??NEI
# Number of unique event types
length(unique(data$EVTYPE))
# Number of unique event types
length(unique()(data$EVTYPE))
?unique
#-------------------------------------------------------------------------------------
# Load Data
storm <- read.csv("repdata_data_StormData.csv", header=TRUE, stringsAsFactors = FALSE)
# Load Data
storm <- read.csv("repdata_data_StormData.csv", header=TRUE, stringsAsFactors = FALSE)
getwd()
setwd(C:/Users/Gn0145/Desktop/-/Ass2)
setwd("C:/Users/Gn0145/Desktop/-/Ass2")
getwd()
setwd("C:/Users/Gn0145/Desktop/-/Ass2")
library("swirl", lib.loc="~/R/win-library/3.2")
library(swirl)
install_from_swirl("Statistical Inference")
library("swirl", lib.loc="~/R/win-library/3.2")
swirl()
library("swirl", lib.loc="~/R/win-library/3.2")
library(swirl)
install_course_zip("C:\Users\Gn0145\Desktop\-", multi=TRUE, which_course="Statistical_Inference")
install_course_zip("C:/Users/Gn0145/Desktop/-", multi=TRUE, which_course="Statistical_Inference")
install_course_zip("C:\Users\Gn0145\Desktop\-", multi=TRUE, which_course="Statistical_Inference")
install_course_zip("~/Downloads/swirl_courses-master.zip", multi=TRUE)
install_course_zip("~/Downloads/swirl_courses-master.zip", multi=TRUE)
install_course_zip("~/Downloads/swirl_courses-master.zip", multi=TRUE)
install_course_zip("~/Downloads/swirl_courses-master.zip", multi=TRUE, which_course="Statistical Inference")
library(swirl)
install_course_zip("~/Downloads/swirl_courses-master.zip", multi=TRUE, which_course="R Programming")
install_course_zip("~/Downloads/swirl_courses-master.zip", which_course="R Programming")
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
minus <- sum(x*w)/sum(w)
fin <- sum(w*(x-minus)^2)
c(minus,fin)
fin
fin <- sum(w*(x-minus)^2)
fin
c(minus,fin)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
x<-c(x,x*-1)
y<-c(y,y*-1)
#mean(y)
#plot(x,y)
cor(x,y)*sd(y)/sd(x)
data(mtcars)
head(mtcars)
x<-mtcars$wt
y<-mtcars$mpg
cor(x,y)*sd(y)/sd(x)
1.5*4
x<-c(x,x*-1)
y<-c(y,y*-1)
#mean(y)
#plot(x,y)
cor(x,y)*sd(y)/sd(x)
--------------------
data(mtcars)
head(mtcars)
x<-mtcars$wt
y<-mtcars$mpg
cor(x,y)*sd(y)/sd(x)
--------------------
1.5*4
1.5*.4
b1<-cor(x,y)*sd(y)/sd(x)
b0<-mean(y)-b1*mean(x)
mean
mean
mean
mean
mean
mean
mean
mean
mean
mean
install.packages("swirl")
library(swirl)
ls()
rm(list=ls())
swirl()
Sys.which("pdflatex")
## ----cache=TRUE----------------------------------------------------------
library(RCurl)
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
train_data <- read.csv(text=getURL(train_url), na.strings=c("", "NA"))
test_data <- read.csv(text=getURL(test_url), na.strings=c("", "NA"))
## ------------------------------------------------------------------------
train_data$X <- NULL
## ------------------------------------------------------------------------
cols_to_remove <- c("user_name", "raw_timestamp_part_1",
"raw_timestamp_part_2", "cvtd_timestamp")
for (col in cols_to_remove) {
train_data[, col] <- NULL
}
## ------------------------------------------------------------------------
NAs <- apply(train_data,2,function(x) {sum(is.na(x))})
train_data <- train_data[,which(NAs == 0)]
## ----message=FALSE-------------------------------------------------------
library(caret)
nsv <- nearZeroVar(train_data)
train_data <- train_data[-nsv]
test_data <- test_data[-nsv]
## ------------------------------------------------------------------------
names(train_data)
## ----cache=TRUE----------------------------------------------------------
library(randomForest)
set.seed(1)
obs <- c()
preds <- c()
for(i in 1:10) {
intrain = sample(1:dim(train_data)[1], size=dim(train_data)[1] * 0.8, replace=F)
train_cross = train_data[intrain,]
test_cross = train_data[-intrain,]
rf <- randomForest(classe ~ ., data=train_cross)
obs <- c(obs, test_cross$classe)
preds <- c(preds, predict(rf, test_cross))
}
## ------------------------------------------------------------------------
conf_mat <- confusionMatrix(table(preds, obs))
conf_mat$table
## ----cache=TRUE----------------------------------------------------------
model <- randomForest(classe ~ ., data=train_data)
set.seed(1)
obs <- c()
preds <- c()
for(i in 1:10) {
intrain = sample(1:dim(train_data)[1], size=dim(train_data)[1] * 0.8, replace=F)
train_cross = train_data[intrain,]
test_cross = train_data[-intrain,]
rf <- randomForest(classe ~ ., data=train_cross)
obs <- c(obs, test_cross$classe)
preds <- c(preds, predict(rf, test_cross))
}
## ------------------------------------------------------------------------
library(RCurl)
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
train_data <- read.csv(text=getURL(train_url), na.strings=c("", "NA"))
test_data <- read.csv(text=getURL(test_url), na.strings=c("", "NA"))
file.edit('~/.Rprofile')
options(rpubs.upload.method = "internal")
library(RCurl)
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
train_data <- read.csv(text=getURL(train_url), na.strings=c("", "NA"))
library(RCurl)
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
train_data <- read.csv(url(train_url), na.strings=c("NA","#DIV/0!",""))
getwd()
setwd("C:/Users/Gn0145/Desktop/-/8-Practical Machine Learning/Assignment")
library(RCurl)
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
train_data <- read.csv(url(train_url), na.strings=c("NA","#DIV/0!",""))
test_data <- read.csv(text=getURL(test_url), na.strings=c("NA","#DIV/0!",""))
test_data <- read.csv(url(test_url), na.strings=c("NA","#DIV/0!",""))
train_data$X <- NULL
## ------------------------------------------------------------------------
cols_to_remove <- c("user_name", "raw_timestamp_part_1",
"raw_timestamp_part_2", "cvtd_timestamp")
for (col in cols_to_remove) {
train_data[, col] <- NULL
}
## ------------------------------------------------------------------------
NAs <- apply(train_data,2,function(x) {sum(is.na(x))})
train_data <- train_data[,which(NAs == 0)]
## ----message=FALSE-------------------------------------------------------
library(caret)
nsv <- nearZeroVar(train_data)
train_data <- train_data[-nsv]
test_data <- test_data[-nsv]
## ------------------------------------------------------------------------
names(train_data)
## ----cache=TRUE----------------------------------------------------------
library(randomForest)
set.seed(1)
obs <- c()
preds <- c()
for(i in 1:10) {
intrain = sample(1:dim(train_data)[1], size=dim(train_data)[1] * 0.8, replace=F)
train_cross = train_data[intrain,]
test_cross = train_data[-intrain,]
rf <- randomForest(classe ~ ., data=train_cross)
obs <- c(obs, test_cross$classe)
preds <- c(preds, predict(rf, test_cross))
}
## ------------------------------------------------------------------------
conf_mat <- confusionMatrix(table(preds, obs))
conf_mat$table
## ----cache=TRUE----------------------------------------------------------
model <- randomForest(classe ~ ., data=train_data)
# Load model and test data (model and test_data)
load("rf_model.RData", verbose=TRUE)
# Load model and test data (model and test_data)
load("rf_model.RData", verbose=TRUE)
load("test_data.RData", verbose=TRUE)
getwd()
setwd("C:/Users/Gn0145/Desktop/-/8-Practical Machine Learning/Assignment/prediction")
load("rf_model.RData", verbose=TRUE)
load("test_data.RData", verbose=TRUE)
# Function to write predictions to separate files
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
# Prediction
library(randomForest)
library(caret)
answers <- predict(model, test_data)
# write answers to files
pml_write_files(answers)
library("knitr", lib.loc="~/R/win-library/3.2")
library("knitr")
getwd()
setwd("C:/Users/Gn0145/Desktop/-/7-Regression Model")
getwd()
setwd("C:/Users/Gn0145/Desktop/-/8-Practical Machine Learning/Assignment/writeup")
